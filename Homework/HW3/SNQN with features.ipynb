{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !chmod -R 755 .","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:26:46.519545Z","iopub.execute_input":"2023-11-24T22:26:46.520348Z","iopub.status.idle":"2023-11-24T22:26:46.525140Z","shell.execute_reply.started":"2023-11-24T22:26:46.520313Z","shell.execute_reply":"2023-11-24T22:26:46.524189Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install gdown","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:39:14.813218Z","iopub.execute_input":"2023-11-24T22:39:14.813723Z","iopub.status.idle":"2023-11-24T22:39:27.402225Z","shell.execute_reply.started":"2023-11-24T22:39:14.813695Z","shell.execute_reply":"2023-11-24T22:39:27.401181Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.7.22)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import gdown\n\n# a file\n# url = \"https://drive.google.com/drive/folders/1gGryyqiQtPVWtGbv902WfSsULpqONexa?usp=drive_link\"\nid = '14NM3x99gKWjqbOy11qSaQ9g_URHbxgs4'\noutput = \"/kaggle/\"\ngdown.download(id=id, output=output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:39:27.404783Z","iopub.execute_input":"2023-11-24T22:39:27.405214Z","iopub.status.idle":"2023-11-24T22:39:29.386570Z","shell.execute_reply.started":"2023-11-24T22:39:27.405163Z","shell.execute_reply":"2023-11-24T22:39:29.385625Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (uriginal): https://drive.google.com/uc?id=14NM3x99gKWjqbOy11qSaQ9g_URHbxgs4\nFrom (redirected): https://drive.google.com/uc?id=14NM3x99gKWjqbOy11qSaQ9g_URHbxgs4&confirm=t&uuid=580056f3-566a-437a-b224-c90f7fa49982\nTo: /kaggle/Kaggle.zip\n100%|██████████| 84.4M/84.4M [00:00<00:00, 115MB/s] \n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/Kaggle.zip'"},"metadata":{}}]},{"cell_type":"code","source":"!unzip /kaggle/Kaggle.zip","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:39:29.387700Z","iopub.execute_input":"2023-11-24T22:39:29.388082Z","iopub.status.idle":"2023-11-24T22:39:33.397442Z","shell.execute_reply.started":"2023-11-24T22:39:29.388055Z","shell.execute_reply":"2023-11-24T22:39:33.396247Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Archive:  /kaggle/Kaggle.zip\n   creating: Kaggle/\n  inflating: Kaggle/.DS_Store        \n  inflating: __MACOSX/Kaggle/._.DS_Store  \n  inflating: Kaggle/utility.py       \n  inflating: Kaggle/NextItNetModules.py  \n  inflating: Kaggle/SASRecModules.py  \n   creating: Kaggle/__pycache__/\n  inflating: Kaggle/test.py          \n  inflating: Kaggle/DQN_NS.py        \n  inflating: Kaggle/replay_buffer.py  \n  inflating: Kaggle/SNQN.py          \n  inflating: Kaggle/preprocess_kaggle.py  \n  inflating: Kaggle/SNQN_new_with_features.py  \n  inflating: Kaggle/split_data.py    \n  inflating: Kaggle/SNQN_new.py      \n   creating: Kaggle/data/\n  inflating: Kaggle/pop.py           \n  inflating: Kaggle/SA2C.py          \n  inflating: Kaggle/__pycache__/NextItNetModules.cpython-36.pyc  \n  inflating: Kaggle/__pycache__/SASRecModules.cpython-36.pyc  \n  inflating: Kaggle/__pycache__/NextItNetModules.cpython-310.pyc  \n  inflating: Kaggle/__pycache__/utility.cpython-310.pyc  \n  inflating: Kaggle/__pycache__/SASRecModules.cpython-310.pyc  \n  inflating: Kaggle/__pycache__/utility.cpython-36.pyc  \n  inflating: Kaggle/data/sampled_val.df  \n  inflating: Kaggle/data/sorted_events.df  \n  inflating: Kaggle/data/sampled_train.df  \n  inflating: Kaggle/data/item_prop_ohe.csv  \n  inflating: Kaggle/data/sorted_events.csv  \n  inflating: Kaggle/data/replay_buffer.df  \n  inflating: Kaggle/data/events.csv  \n  inflating: Kaggle/data/data_statis.df  \n  inflating: Kaggle/data/pop_dict.txt  \n  inflating: Kaggle/data/sampled_test.df  \n  inflating: Kaggle/data/item_properties.csv  \n","output_type":"stream"}]},{"cell_type":"code","source":"cd Kaggle/","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:39:33.400181Z","iopub.execute_input":"2023-11-24T22:39:33.400893Z","iopub.status.idle":"2023-11-24T22:39:33.407100Z","shell.execute_reply.started":"2023-11-24T22:39:33.400859Z","shell.execute_reply":"2023-11-24T22:39:33.406278Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/Kaggle\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install trfl pandas","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:39:33.408353Z","iopub.execute_input":"2023-11-24T22:39:33.408650Z","iopub.status.idle":"2023-11-24T22:39:45.383998Z","shell.execute_reply.started":"2023-11-24T22:39:33.408625Z","shell.execute_reply":"2023-11-24T22:39:45.382834Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting trfl\n  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from trfl) (1.4.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from trfl) (0.1.8)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from trfl) (1.24.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from trfl) (1.16.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from trfl) (1.15.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nInstalling collected packages: trfl\nSuccessfully installed trfl-1.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# ! python SNQN_new.py --model=GRU --epoch=5","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:36:20.543437Z","iopub.execute_input":"2023-11-24T22:36:20.544404Z","iopub.status.idle":"2023-11-24T22:36:20.548533Z","shell.execute_reply.started":"2023-11-24T22:36:20.544361Z","shell.execute_reply":"2023-11-24T22:36:20.547626Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ls data","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:39:50.311956Z","iopub.execute_input":"2023-11-24T22:39:50.312705Z","iopub.status.idle":"2023-11-24T22:39:51.281103Z","shell.execute_reply.started":"2023-11-24T22:39:50.312648Z","shell.execute_reply":"2023-11-24T22:39:51.280132Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"data_statis.df     item_properties.csv  sampled_test.df   sorted_events.csv\nevents.csv         pop_dict.txt         sampled_train.df  sorted_events.df\nitem_prop_ohe.csv  replay_buffer.df     sampled_val.df\n","output_type":"stream"}]},{"cell_type":"code","source":"! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.1","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:39:54.090684Z","iopub.execute_input":"2023-11-24T22:39:54.091061Z","iopub.status.idle":"2023-11-25T00:02:12.249294Z","shell.execute_reply.started":"2023-11-24T22:39:54.091030Z","shell.execute_reply":"2023-11-25T00:02:12.248220Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/kaggle/working/Kaggle/SNQN_new_with_features.py:85: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n/kaggle/working/Kaggle/SNQN_new_with_features.py:212: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n/kaggle/working/Kaggle/SNQN_new_with_features.py:215: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n/kaggle/working/Kaggle/SNQN_new_with_features.py:217: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n  self.features_layer = tf.compat.v1.layers.dense(self.features,self.hidden_size,use_bias=True,activation = None)\nthe loss in 200th batch is: 11.378014\nthe loss in 400th batch is: 11.703457\nthe loss in 600th batch is: 11.531125\nthe loss in 800th batch is: 11.287374\nthe loss in 1000th batch is: 11.252516\nthe loss in 1200th batch is: 11.290282\nthe loss in 1400th batch is: 11.100431\nthe loss in 1600th batch is: 11.155000\nthe loss in 1800th batch is: 10.932472\nthe loss in 2000th batch is: 10.964718\nthe loss in 2200th batch is: 10.932515\nthe loss in 2400th batch is: 10.901951\nthe loss in 2600th batch is: 10.917852\nthe loss in 2800th batch is: 10.902759\nthe loss in 3000th batch is: 10.835882\nthe loss in 3200th batch is: 10.882853\nthe loss in 3400th batch is: 10.828333\nthe loss in 3600th batch is: 10.792470\nthe loss in 3800th batch is: 10.693182\nthe loss in 4000th batch is: 10.663772\nthe loss in 4200th batch is: 10.592307\nthe loss in 4400th batch is: 10.534250\nthe loss in 4600th batch is: 10.342700\nthe loss in 4800th batch is: 10.581702\nthe loss in 5000th batch is: 10.789047\nthe loss in 5200th batch is: 10.352245\nthe loss in 5400th batch is: 10.623329\nthe loss in 5600th batch is: 10.223569\nthe loss in 5800th batch is: 10.330580\nthe loss in 6000th batch is: 10.464149\nthe loss in 6200th batch is: 10.317551\nthe loss in 6400th batch is: 10.256943\nthe loss in 6600th batch is: 10.343325\nthe loss in 6800th batch is: 10.366439\nthe loss in 7000th batch is: 10.228130\nthe loss in 7200th batch is: 10.197817\nthe loss in 7400th batch is: 10.316353\nthe loss in 7600th batch is: 10.064329\nthe loss in 7800th batch is: 10.240582\nthe loss in 8000th batch is: 10.071001\nthe loss in 8200th batch is: 10.155104\nthe loss in 8400th batch is: 10.186701\nthe loss in 8600th batch is: 10.592416\nthe loss in 8800th batch is: 10.287948\nthe loss in 9000th batch is: 10.131128\nthe loss in 9200th batch is: 10.255369\nthe loss in 9400th batch is: 10.060040\nthe loss in 9600th batch is: 10.205731\nthe loss in 9800th batch is: 10.101375\nthe loss in 10000th batch is: 10.188779\nthe loss in 10200th batch is: 10.073606\nthe loss in 10400th batch is: 10.249131\nthe loss in 10600th batch is: 9.862673\nthe loss in 10800th batch is: 9.899236\nthe loss in 11000th batch is: 9.824553\nthe loss in 11200th batch is: 9.776564\nthe loss in 11400th batch is: 9.970218\nthe loss in 11600th batch is: 9.820200\nthe loss in 11800th batch is: 9.811543\nthe loss in 12000th batch is: 10.128112\nthe loss in 12200th batch is: 9.595634\nthe loss in 12400th batch is: 9.822469\nthe loss in 12600th batch is: 9.896150\nthe loss in 12800th batch is: 9.846256\nthe loss in 13000th batch is: 9.577015\nthe loss in 13200th batch is: 9.735275\nthe loss in 13400th batch is: 9.894041\nthe loss in 13600th batch is: 9.709919\nthe loss in 13800th batch is: 9.676779\nthe loss in 14000th batch is: 9.823704\nthe loss in 14200th batch is: 9.844161\nthe loss in 14400th batch is: 9.912076\nthe loss in 14600th batch is: 9.768517\nthe loss in 14800th batch is: 9.754499\nthe loss in 15000th batch is: 10.073950\nthe loss in 15200th batch is: 9.544374\nthe loss in 15400th batch is: 9.809994\nthe loss in 15600th batch is: 9.743114\nthe loss in 15800th batch is: 9.629857\nthe loss in 16000th batch is: 9.733980\nthe loss in 16200th batch is: 9.519453\nthe loss in 16400th batch is: 9.606567\nthe loss in 16600th batch is: 9.723495\nthe loss in 16800th batch is: 9.433899\nthe loss in 17000th batch is: 9.543375\nthe loss in 17200th batch is: 9.667685\nthe loss in 17400th batch is: 9.167085\nthe loss in 17600th batch is: 9.484268\nthe loss in 17800th batch is: 9.605248\nthe loss in 18000th batch is: 9.622742\nthe loss in 18200th batch is: 9.470080\nthe loss in 18400th batch is: 9.464366\nthe loss in 18600th batch is: 9.472908\nthe loss in 18800th batch is: 9.368046\nthe loss in 19000th batch is: 9.582174\nthe loss in 19200th batch is: 9.652044\n#############################################################\ntotal clicks: 118306, total purchase:5291\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncumulative reward @ 5: 3891.200000\nclicks hr ndcg @ 5 : 0.107273, 0.090943\npurchase hr and ndcg @5 : 0.255717, 0.220330\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncumulative reward @ 10: 4361.000000\nclicks hr ndcg @ 10 : 0.120493, 0.095217\npurchase hr and ndcg @10 : 0.285390, 0.229856\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncumulative reward @ 15: 4640.800000\nclicks hr ndcg @ 15 : 0.128768, 0.097402\npurchase hr and ndcg @15 : 0.301266, 0.234081\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncumulative reward @ 20: 4813.200000\nclicks hr ndcg @ 20 : 0.133814, 0.098596\npurchase hr and ndcg @20 : 0.311283, 0.236437\n#############################################################\n","output_type":"stream"}]},{"cell_type":"code","source":"! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.2","metadata":{"execution":{"iopub.status.busy":"2023-11-25T00:02:12.251638Z","iopub.execute_input":"2023-11-25T00:02:12.252571Z","iopub.status.idle":"2023-11-25T01:24:45.835946Z","shell.execute_reply.started":"2023-11-25T00:02:12.252528Z","shell.execute_reply":"2023-11-25T01:24:45.834731Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/kaggle/working/Kaggle/SNQN_new_with_features.py:85: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n/kaggle/working/Kaggle/SNQN_new_with_features.py:212: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n/kaggle/working/Kaggle/SNQN_new_with_features.py:215: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n/kaggle/working/Kaggle/SNQN_new_with_features.py:217: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n  self.features_layer = tf.compat.v1.layers.dense(self.features,self.hidden_size,use_bias=True,activation = None)\nthe loss in 200th batch is: 11.384401\nthe loss in 400th batch is: 11.649719\nthe loss in 600th batch is: 11.657927\nthe loss in 800th batch is: 11.368053\nthe loss in 1000th batch is: 11.073269\nthe loss in 1200th batch is: 11.001225\nthe loss in 1400th batch is: 10.909673\nthe loss in 1600th batch is: 11.184868\nthe loss in 1800th batch is: 10.855921\nthe loss in 2000th batch is: 10.886360\nthe loss in 2200th batch is: 10.734078\nthe loss in 2400th batch is: 10.900715\nthe loss in 2600th batch is: 11.056023\nthe loss in 2800th batch is: 10.669811\nthe loss in 3000th batch is: 10.665911\nthe loss in 3200th batch is: 10.540492\nthe loss in 3400th batch is: 10.498845\nthe loss in 3600th batch is: 10.428552\nthe loss in 3800th batch is: 10.424718\nthe loss in 4000th batch is: 10.234807\nthe loss in 4200th batch is: 10.300573\nthe loss in 4400th batch is: 10.458965\nthe loss in 4600th batch is: 10.257224\nthe loss in 4800th batch is: 10.205543\nthe loss in 5000th batch is: 10.204609\nthe loss in 5200th batch is: 10.334306\nthe loss in 5400th batch is: 10.013392\nthe loss in 5600th batch is: 10.108360\nthe loss in 5800th batch is: 10.222851\nthe loss in 6000th batch is: 9.909781\nthe loss in 6200th batch is: 10.355738\nthe loss in 6400th batch is: 10.112597\nthe loss in 6600th batch is: 10.060098\nthe loss in 6800th batch is: 10.170087\nthe loss in 7000th batch is: 9.958397\nthe loss in 7200th batch is: 10.222198\nthe loss in 7400th batch is: 9.785015\nthe loss in 7600th batch is: 9.984900\nthe loss in 7800th batch is: 9.993970\nthe loss in 8000th batch is: 9.705482\nthe loss in 8200th batch is: 9.913551\nthe loss in 8400th batch is: 9.915065\nthe loss in 8600th batch is: 9.730977\nthe loss in 8800th batch is: 9.831229\nthe loss in 9000th batch is: 9.985495\nthe loss in 9200th batch is: 9.803696\nthe loss in 9400th batch is: 9.815256\nthe loss in 9600th batch is: 9.600285\nthe loss in 9800th batch is: 9.512815\nthe loss in 10000th batch is: 9.711835\nthe loss in 10200th batch is: 9.796366\nthe loss in 10400th batch is: 9.753469\nthe loss in 10600th batch is: 9.759079\nthe loss in 10800th batch is: 9.872703\nthe loss in 11000th batch is: 9.667906\nthe loss in 11200th batch is: 9.464225\nthe loss in 11400th batch is: 9.464090\nthe loss in 11600th batch is: 9.966856\nthe loss in 11800th batch is: 9.419952\nthe loss in 12000th batch is: 9.494701\nthe loss in 12200th batch is: 9.649454\nthe loss in 12400th batch is: 9.464436\nthe loss in 12600th batch is: 9.717066\nthe loss in 12800th batch is: 9.521943\nthe loss in 13000th batch is: 9.567820\nthe loss in 13200th batch is: 9.646673\nthe loss in 13400th batch is: 9.720377\nthe loss in 13600th batch is: 9.745599\nthe loss in 13800th batch is: 9.777898\nthe loss in 14000th batch is: 9.704266\nthe loss in 14200th batch is: 9.698408\nthe loss in 14400th batch is: 9.245207\nthe loss in 14600th batch is: 9.365112\nthe loss in 14800th batch is: 9.219707\nthe loss in 15400th batch is: 9.365973\nthe loss in 15600th batch is: 9.599714\nthe loss in 15800th batch is: 9.411700\nthe loss in 16000th batch is: 9.707010\nthe loss in 16200th batch is: 9.155495\nthe loss in 16400th batch is: 9.230206\nthe loss in 16600th batch is: 9.362397\nthe loss in 16800th batch is: 9.452727\nthe loss in 17000th batch is: 9.391045\nthe loss in 17200th batch is: 9.008738\nthe loss in 17400th batch is: 9.440377\nthe loss in 17600th batch is: 9.295126\nthe loss in 17800th batch is: 9.441964\nthe loss in 18000th batch is: 8.719279\nthe loss in 18200th batch is: 9.303836\nthe loss in 18400th batch is: 9.209266\nthe loss in 18600th batch is: 9.364197\nthe loss in 18800th batch is: 9.496109\nthe loss in 19000th batch is: 9.152137\nthe loss in 19200th batch is: 9.531954\n#############################################################\ntotal clicks: 118306, total purchase:5291\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncumulative reward @ 5: 3963.600000\nclicks hr ndcg @ 5 : 0.109741, 0.093468\npurchase hr and ndcg @5 : 0.258363, 0.227042\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncumulative reward @ 10: 4369.800000\nclicks hr ndcg @ 10 : 0.122471, 0.097577\npurchase hr and ndcg @10 : 0.278208, 0.233413\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncumulative reward @ 15: 4616.000000\nclicks hr ndcg @ 15 : 0.130129, 0.099607\npurchase hr and ndcg @15 : 0.290493, 0.236654\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncumulative reward @ 20: 4814.200000\nclicks hr ndcg @ 20 : 0.135885, 0.100969\npurchase hr and ndcg @20 : 0.302211, 0.239430\n#############################################################\n","output_type":"stream"}]},{"cell_type":"code","source":"! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.5","metadata":{"execution":{"iopub.status.busy":"2023-11-25T01:30:46.218240Z","iopub.execute_input":"2023-11-25T01:30:46.218581Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/kaggle/working/Kaggle/SNQN_new_with_features.py:85: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n/kaggle/working/Kaggle/SNQN_new_with_features.py:212: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n/kaggle/working/Kaggle/SNQN_new_with_features.py:215: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n/kaggle/working/Kaggle/SNQN_new_with_features.py:217: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n  self.features_layer = tf.compat.v1.layers.dense(self.features,self.hidden_size,use_bias=True,activation = None)\nthe loss in 200th batch is: 11.359965\nthe loss in 400th batch is: 11.510338\nthe loss in 600th batch is: 11.642828\nthe loss in 800th batch is: 11.231221\nthe loss in 1000th batch is: 10.961859\nthe loss in 1200th batch is: 10.865892\nthe loss in 1400th batch is: 10.730684\nthe loss in 1600th batch is: 10.638948\nthe loss in 1800th batch is: 10.593769\nthe loss in 2000th batch is: 10.550879\nthe loss in 2200th batch is: 10.646200\nthe loss in 2400th batch is: 10.566029\nthe loss in 2600th batch is: 10.661630\nthe loss in 2800th batch is: 10.340390\nthe loss in 3000th batch is: 10.493116\nthe loss in 3200th batch is: 10.391886\nthe loss in 3400th batch is: 10.147554\nthe loss in 3600th batch is: 10.229715\nthe loss in 3800th batch is: 10.482197\nthe loss in 4000th batch is: 10.148531\nthe loss in 4200th batch is: 10.128680\nthe loss in 4400th batch is: 9.836557\nthe loss in 4600th batch is: 10.058531\nthe loss in 4800th batch is: 10.283908\nthe loss in 5000th batch is: 10.094037\nthe loss in 5200th batch is: 10.181755\nthe loss in 5400th batch is: 10.030272\nthe loss in 5600th batch is: 9.764321\nthe loss in 5800th batch is: 9.931023\nthe loss in 6000th batch is: 10.214111\nthe loss in 6200th batch is: 10.062959\nthe loss in 6400th batch is: 9.645260\nthe loss in 6600th batch is: 9.758479\nthe loss in 6800th batch is: 9.511454\nthe loss in 7000th batch is: 9.776035\nthe loss in 7200th batch is: 9.639386\nthe loss in 7400th batch is: 9.904753\nthe loss in 7600th batch is: 9.659137\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}