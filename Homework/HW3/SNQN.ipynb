{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe6jIQxyHr5v",
        "outputId": "be712bd2-754d-4c09-c709-7e68f894b8aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle\n",
            "data\t\t     preprocess_kaggle.py  report_SNQN.txt   SNQN_new.py\t\ttest.py\n",
            "DQN_NS.py\t     __pycache__\t   SA2C_new.py\t     SNQN_new_with_features.py\tutility.py\n",
            "NextItNetModules.py  replay_buffer.py\t   SA2C.py\t     SNQN.py\n",
            "pop.py\t\t     report_SA2C.txt\t   SASRecModules.py  split_data.py\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PROJ_DIR = '/content/drive/MyDrive/AIPI 531 HW3/Kaggle/'   ## give your drive folder location\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using https://www.tensorflow.org/guide/migrate/upgrade to change code of SNQN and SA2C"
      ],
      "metadata": {
        "id": "7BlGmKufIcBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !tf_upgrade_v2 \\\n",
        "#   --infile 'SNQN.py' \\\n",
        "#   --outfile 'SNQN_new.py' \\\n",
        "#   --reportfile report_SNQN.txt"
      ],
      "metadata": {
        "id": "07gS5tgQNQyJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Addtional Changes\n",
        "#1. Added 'tf.compat.v1.disable_eager_execution()' after init()\n",
        "#2. Replaced 'tf.contrib.layers.fully_connected' with 'tf.compat.v1.layers.dense' near line 207\n",
        "#3. Changed 'activation_fn' to 'activation'\n",
        "#4. Changed 'scope' to 'name'"
      ],
      "metadata": {
        "id": "Yvq5LfWyYYGp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tf_upgrade_v2 \\\n",
        "#   --infile 'SA2C.py' \\\n",
        "#   --outfile 'SA2C_new.py' \\\n",
        "#   --reportfile report_SA2C.txt"
      ],
      "metadata": {
        "id": "WcOUmyaTIDI6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trfl pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4isH4u9tW7tK",
        "outputId": "f59fa45a-a46d-4f48-e611-43ab4fd3ae44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trfl in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trfl) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SNQN without features"
      ],
      "metadata": {
        "id": "_FjTNnfMak6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python SNQN_new.py --model=GRU --epoch=5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxrSvJ0uITpm",
        "outputId": "755f8d52-3c27-4f7c-eeba-d2e6fd7f5fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-24 18:39:11.503646: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 18:39:11.503703: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 18:39:11.503748: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 18:39:11.514485: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 18:39:13.400808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new.py:80: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new.py:79: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "2023-11-24 18:39:18.126743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:18.167421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:18.167789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:18.169462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:18.169756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:18.169977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:19.291715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:19.292141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:19.292310: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-24 18:39:19.292394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:19.292583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new.py:207: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new.py:210: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "2023-11-24 18:39:25.375360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:25.375720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:25.375919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:25.376152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:25.376325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:25.376459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-11-24 18:39:25.400589: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.000000\n",
            "clicks hr ndcg @ 5 : 0.000042, 0.000030\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.800000\n",
            "clicks hr ndcg @ 10 : 0.000118, 0.000054\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 5.000000\n",
            "clicks hr ndcg @ 15 : 0.000169, 0.000067\n",
            "purchase hr and ndcg @15 : 0.000189, 0.000051\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6.600000\n",
            "clicks hr ndcg @ 20 : 0.000237, 0.000083\n",
            "purchase hr and ndcg @20 : 0.000189, 0.000051\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.831070\n",
            "the loss in 400th batch is: 10.708863\n",
            "the loss in 600th batch is: 10.473969\n",
            "the loss in 800th batch is: 10.256775\n",
            "the loss in 1000th batch is: 10.302694\n",
            "the loss in 1200th batch is: 10.187847\n",
            "the loss in 1400th batch is: 9.911209\n",
            "the loss in 1600th batch is: 9.684079\n",
            "the loss in 1800th batch is: 9.965717\n",
            "the loss in 2000th batch is: 9.596400\n",
            "the loss in 2200th batch is: 9.612836\n",
            "the loss in 2400th batch is: 9.414681\n",
            "the loss in 2600th batch is: 9.315511\n",
            "the loss in 2800th batch is: 9.027935\n",
            "the loss in 3000th batch is: 8.892451\n",
            "the loss in 3200th batch is: 8.695235\n",
            "the loss in 3400th batch is: 9.019030\n",
            "the loss in 3600th batch is: 8.995421\n",
            "the loss in 3800th batch is: 8.723010\n",
            "the loss in 4000th batch is: 8.671647\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5940.200000\n",
            "clicks hr ndcg @ 5 : 0.170456, 0.134840\n",
            "purchase hr and ndcg @5 : 0.360423, 0.307851\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6870.200000\n",
            "clicks hr ndcg @ 10 : 0.201816, 0.144975\n",
            "purchase hr and ndcg @10 : 0.395955, 0.319366\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7418.000000\n",
            "clicks hr ndcg @ 15 : 0.220403, 0.149887\n",
            "purchase hr and ndcg @15 : 0.416367, 0.324739\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7792.600000\n",
            "clicks hr ndcg @ 20 : 0.232981, 0.152860\n",
            "purchase hr and ndcg @20 : 0.430920, 0.328163\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.361216\n",
            "the loss in 4400th batch is: 8.552400\n",
            "the loss in 4600th batch is: 7.998997\n",
            "the loss in 4800th batch is: 8.344571\n",
            "the loss in 5000th batch is: 8.101270\n",
            "the loss in 5200th batch is: 8.191595\n",
            "the loss in 5400th batch is: 8.073001\n",
            "the loss in 5600th batch is: 7.812063\n",
            "the loss in 5800th batch is: 8.138997\n",
            "the loss in 6000th batch is: 7.824451\n",
            "the loss in 6200th batch is: 7.857933\n",
            "the loss in 6400th batch is: 8.025812\n",
            "the loss in 6600th batch is: 7.361782\n",
            "the loss in 6800th batch is: 7.613865\n",
            "the loss in 7000th batch is: 7.781521\n",
            "the loss in 7200th batch is: 6.623374\n",
            "the loss in 7400th batch is: 7.506742\n",
            "the loss in 7600th batch is: 7.225129\n",
            "the loss in 7800th batch is: 6.936631\n",
            "the loss in 8000th batch is: 6.949760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SNQN with Features"
      ],
      "metadata": {
        "id": "TjdXc3zlbz-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "t\n",
        "# df = pd.read_csv('/content/drive/MyDrive/AIPI 531 HW3/Kaggle/data/item_prop_ohe.csv')"
      ],
      "metadata": {
        "id": "PyAc-c4AZF-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df"
      ],
      "metadata": {
        "id": "pU_6Q4GccoR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.1"
      ],
      "metadata": {
        "id": "QDEP-4J4kzmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.2"
      ],
      "metadata": {
        "id": "9zGmrAIkcosv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.5"
      ],
      "metadata": {
        "id": "_DgcgFuzdb2A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}