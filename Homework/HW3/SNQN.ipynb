{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"outputs":[],"source":["# github repo\n","https://github.com/rishabhshah13/AIPI531/tree/main/Homework/HW3"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T22:39:14.813723Z","iopub.status.busy":"2023-11-24T22:39:14.813218Z","iopub.status.idle":"2023-11-24T22:39:27.402225Z","shell.execute_reply":"2023-11-24T22:39:27.401181Z","shell.execute_reply.started":"2023-11-24T22:39:14.813695Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gdown\n","  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\n","Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\n","Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.7.22)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n","Installing collected packages: gdown\n","Successfully installed gdown-4.7.1\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install gdown"]},{"cell_type":"markdown","metadata":{},"source":["### Downloading the processed dataset and code from gdrive"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T22:39:27.405214Z","iopub.status.busy":"2023-11-24T22:39:27.404783Z","iopub.status.idle":"2023-11-24T22:39:29.386570Z","shell.execute_reply":"2023-11-24T22:39:29.385625Z","shell.execute_reply.started":"2023-11-24T22:39:27.405163Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From (uriginal): https://drive.google.com/uc?id=14NM3x99gKWjqbOy11qSaQ9g_URHbxgs4\n","From (redirected): https://drive.google.com/uc?id=14NM3x99gKWjqbOy11qSaQ9g_URHbxgs4&confirm=t&uuid=580056f3-566a-437a-b224-c90f7fa49982\n","To: /kaggle/Kaggle.zip\n","100%|██████████| 84.4M/84.4M [00:00<00:00, 115MB/s] \n"]},{"data":{"text/plain":["'/kaggle/Kaggle.zip'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import gdown\n","\n","# a file\n","# url = \"https://drive.google.com/drive/folders/1gGryyqiQtPVWtGbv902WfSsULpqONexa?usp=drive_link\"\n","id = '14NM3x99gKWjqbOy11qSaQ9g_URHbxgs4'\n","output = \"/kaggle/\"\n","gdown.download(id=id, output=output, quiet=False)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T22:39:29.388082Z","iopub.status.busy":"2023-11-24T22:39:29.387700Z","iopub.status.idle":"2023-11-24T22:39:33.397442Z","shell.execute_reply":"2023-11-24T22:39:33.396247Z","shell.execute_reply.started":"2023-11-24T22:39:29.388055Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  /kaggle/Kaggle.zip\n","   creating: Kaggle/\n","  inflating: Kaggle/.DS_Store        \n","  inflating: __MACOSX/Kaggle/._.DS_Store  \n","  inflating: Kaggle/utility.py       \n","  inflating: Kaggle/NextItNetModules.py  \n","  inflating: Kaggle/SASRecModules.py  \n","   creating: Kaggle/__pycache__/\n","  inflating: Kaggle/test.py          \n","  inflating: Kaggle/DQN_NS.py        \n","  inflating: Kaggle/replay_buffer.py  \n","  inflating: Kaggle/SNQN.py          \n","  inflating: Kaggle/preprocess_kaggle.py  \n","  inflating: Kaggle/SNQN_new_with_features.py  \n","  inflating: Kaggle/split_data.py    \n","  inflating: Kaggle/SNQN_new.py      \n","   creating: Kaggle/data/\n","  inflating: Kaggle/pop.py           \n","  inflating: Kaggle/SA2C.py          \n","  inflating: Kaggle/__pycache__/NextItNetModules.cpython-36.pyc  \n","  inflating: Kaggle/__pycache__/SASRecModules.cpython-36.pyc  \n","  inflating: Kaggle/__pycache__/NextItNetModules.cpython-310.pyc  \n","  inflating: Kaggle/__pycache__/utility.cpython-310.pyc  \n","  inflating: Kaggle/__pycache__/SASRecModules.cpython-310.pyc  \n","  inflating: Kaggle/__pycache__/utility.cpython-36.pyc  \n","  inflating: Kaggle/data/sampled_val.df  \n","  inflating: Kaggle/data/sorted_events.df  \n","  inflating: Kaggle/data/sampled_train.df  \n","  inflating: Kaggle/data/item_prop_ohe.csv  \n","  inflating: Kaggle/data/sorted_events.csv  \n","  inflating: Kaggle/data/replay_buffer.df  \n","  inflating: Kaggle/data/events.csv  \n","  inflating: Kaggle/data/data_statis.df  \n","  inflating: Kaggle/data/pop_dict.txt  \n","  inflating: Kaggle/data/sampled_test.df  \n","  inflating: Kaggle/data/item_properties.csv  \n"]}],"source":["!unzip /kaggle/Kaggle.zip"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T22:39:33.400893Z","iopub.status.busy":"2023-11-24T22:39:33.400181Z","iopub.status.idle":"2023-11-24T22:39:33.407100Z","shell.execute_reply":"2023-11-24T22:39:33.406278Z","shell.execute_reply.started":"2023-11-24T22:39:33.400859Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/Kaggle\n"]}],"source":["cd Kaggle/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## DO NOT USE NOW, Addtional changes has been made to the file\n","# !tf_upgrade_v2 \\\n","#   --infile 'SNQN.py' \\\n","#   --outfile 'SNQN_new.py' \\\n","#   --reportfile report_SNQN.txt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Addtional Changes\n","#1. Added 'tf.compat.v1.disable_eager_execution()' after init()\n","#2. Replaced 'tf.contrib.layers.fully_connected' with 'tf.compat.v1.layers.dense' near line 207\n","#3. Changed 'activation_fn' to 'activation'\n","#4. Changed 'scope' to 'name'\n","#5. Using GPU instead of CPU"]},{"cell_type":"markdown","metadata":{},"source":["## Installing Required Libraries"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T22:39:33.408650Z","iopub.status.busy":"2023-11-24T22:39:33.408353Z","iopub.status.idle":"2023-11-24T22:39:45.383998Z","shell.execute_reply":"2023-11-24T22:39:45.382834Z","shell.execute_reply.started":"2023-11-24T22:39:33.408625Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting trfl\n","  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.3)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from trfl) (1.4.0)\n","Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from trfl) (0.1.8)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from trfl) (1.24.3)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from trfl) (1.16.0)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from trfl) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n","Installing collected packages: trfl\n","Successfully installed trfl-1.2.0\n"]}],"source":["!pip install trfl pandas"]},{"cell_type":"markdown","metadata":{},"source":["## SNQN without Features"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T02:53:24.658602Z","iopub.status.busy":"2023-11-25T02:53:24.658296Z","iopub.status.idle":"2023-11-25T04:14:08.483966Z","shell.execute_reply":"2023-11-25T04:14:08.482733Z","shell.execute_reply.started":"2023-11-25T02:53:24.658574Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/kaggle/working/Kaggle/SNQN_new.py:80: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","/kaggle/working/Kaggle/SNQN_new.py:207: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/kaggle/working/Kaggle/SNQN_new.py:210: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","the loss in 200th batch is: 10.857892\n","the loss in 400th batch is: 10.758402\n","the loss in 600th batch is: 10.640245\n","the loss in 800th batch is: 10.300344\n","the loss in 1000th batch is: 10.480021\n","the loss in 1200th batch is: 10.291640\n","the loss in 1400th batch is: 10.352674\n","the loss in 1600th batch is: 10.010108\n","the loss in 1800th batch is: 9.524730\n","the loss in 2000th batch is: 9.511866\n","the loss in 2200th batch is: 9.764797\n","the loss in 2400th batch is: 9.717150\n","the loss in 2600th batch is: 9.374634\n","the loss in 2800th batch is: 9.126180\n","the loss in 3000th batch is: 9.151128\n","the loss in 3200th batch is: 8.800527\n","the loss in 3400th batch is: 9.055316\n","the loss in 3600th batch is: 8.425371\n","the loss in 3800th batch is: 8.411366\n","the loss in 4000th batch is: 8.393002\n","the loss in 4200th batch is: 8.658244\n","the loss in 4400th batch is: 8.758528\n","the loss in 4600th batch is: 8.371055\n","the loss in 4800th batch is: 7.867840\n","the loss in 5000th batch is: 7.886785\n","the loss in 5200th batch is: 8.288091\n","the loss in 5400th batch is: 8.280903\n","the loss in 5600th batch is: 7.968839\n","the loss in 5800th batch is: 8.117955\n","the loss in 6000th batch is: 7.899538\n","the loss in 6200th batch is: 7.811522\n","the loss in 6400th batch is: 7.593465\n","the loss in 6600th batch is: 7.514881\n","the loss in 6800th batch is: 7.425415\n","the loss in 7000th batch is: 7.269538\n","the loss in 7200th batch is: 7.280546\n","the loss in 7400th batch is: 7.242560\n","the loss in 7600th batch is: 7.390268\n","the loss in 7800th batch is: 7.352358\n","the loss in 8000th batch is: 7.228232\n","the loss in 8200th batch is: 7.213015\n","the loss in 8400th batch is: 6.860164\n","the loss in 8600th batch is: 6.907557\n","the loss in 8800th batch is: 7.123828\n","the loss in 9000th batch is: 7.497828\n","the loss in 9200th batch is: 6.933482\n","the loss in 9400th batch is: 6.957600\n","the loss in 9600th batch is: 6.962318\n","the loss in 9800th batch is: 7.085032\n","the loss in 10000th batch is: 6.584086\n","the loss in 10200th batch is: 6.944291\n","the loss in 10400th batch is: 6.915162\n","the loss in 10600th batch is: 6.952200\n","the loss in 10800th batch is: 6.994381\n","the loss in 11000th batch is: 6.742235\n","the loss in 11200th batch is: 6.346994\n","the loss in 11400th batch is: 6.429179\n","the loss in 11600th batch is: 6.441043\n","the loss in 11800th batch is: 7.207431\n","the loss in 12000th batch is: 6.508666\n","the loss in 12200th batch is: 6.395010\n","the loss in 12400th batch is: 6.260037\n","the loss in 12600th batch is: 6.062911\n","the loss in 12800th batch is: 6.508623\n","the loss in 13000th batch is: 6.507088\n","the loss in 13200th batch is: 6.116114\n","the loss in 13400th batch is: 6.304409\n","the loss in 13600th batch is: 6.348944\n","the loss in 13800th batch is: 6.456330\n","the loss in 14000th batch is: 6.467484\n","the loss in 14200th batch is: 6.119038\n","the loss in 14400th batch is: 6.359445\n","the loss in 14600th batch is: 5.903068\n","the loss in 14800th batch is: 6.432653\n","the loss in 15000th batch is: 6.473488\n","the loss in 15200th batch is: 6.345394\n","the loss in 15400th batch is: 6.174195\n","the loss in 15600th batch is: 6.023560\n","the loss in 15800th batch is: 6.045441\n","the loss in 16000th batch is: 6.143954\n","the loss in 16200th batch is: 5.733332\n","the loss in 16400th batch is: 6.110835\n","the loss in 16600th batch is: 6.047049\n","the loss in 16800th batch is: 6.010180\n","the loss in 17000th batch is: 5.933624\n","the loss in 17200th batch is: 6.149951\n","the loss in 17400th batch is: 5.778484\n","the loss in 17600th batch is: 5.831522\n","the loss in 17800th batch is: 6.056667\n","the loss in 18000th batch is: 5.708385\n","the loss in 18200th batch is: 5.787617\n","the loss in 18400th batch is: 5.397330\n","the loss in 18600th batch is: 6.085598\n","the loss in 18800th batch is: 5.545751\n","the loss in 19000th batch is: 5.902330\n","the loss in 19200th batch is: 5.914129\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8979.000000\n","clicks hr ndcg @ 5 : 0.263258, 0.203387\n","purchase hr and ndcg @5 : 0.519751, 0.437260\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10447.200000\n","clicks hr ndcg @ 10 : 0.314447, 0.219983\n","purchase hr and ndcg @10 : 0.568324, 0.453015\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11229.400000\n","clicks hr ndcg @ 15 : 0.341673, 0.227198\n","purchase hr and ndcg @15 : 0.594406, 0.459933\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11794.400000\n","clicks hr ndcg @ 20 : 0.361114, 0.231791\n","purchase hr and ndcg @20 : 0.614251, 0.464617\n","#############################################################\n"]}],"source":["! python SNQN_new.py --model=GRU --epoch=5"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T22:39:50.312705Z","iopub.status.busy":"2023-11-24T22:39:50.311956Z","iopub.status.idle":"2023-11-24T22:39:51.281103Z","shell.execute_reply":"2023-11-24T22:39:51.280132Z","shell.execute_reply.started":"2023-11-24T22:39:50.312648Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data_statis.df     item_properties.csv  sampled_test.df   sorted_events.csv\n","events.csv         pop_dict.txt         sampled_train.df  sorted_events.df\n","item_prop_ohe.csv  replay_buffer.df     sampled_val.df\n"]}],"source":["ls data"]},{"cell_type":"markdown","metadata":{},"source":["## SNQN with Features"]},{"cell_type":"markdown","metadata":{},"source":["### lambda 0.1"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-24T22:39:54.091061Z","iopub.status.busy":"2023-11-24T22:39:54.090684Z","iopub.status.idle":"2023-11-25T00:02:12.249294Z","shell.execute_reply":"2023-11-25T00:02:12.248220Z","shell.execute_reply.started":"2023-11-24T22:39:54.091030Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:85: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:212: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:215: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:217: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.features_layer = tf.compat.v1.layers.dense(self.features,self.hidden_size,use_bias=True,activation = None)\n","the loss in 200th batch is: 11.378014\n","the loss in 400th batch is: 11.703457\n","the loss in 600th batch is: 11.531125\n","the loss in 800th batch is: 11.287374\n","the loss in 1000th batch is: 11.252516\n","the loss in 1200th batch is: 11.290282\n","the loss in 1400th batch is: 11.100431\n","the loss in 1600th batch is: 11.155000\n","the loss in 1800th batch is: 10.932472\n","the loss in 2000th batch is: 10.964718\n","the loss in 2200th batch is: 10.932515\n","the loss in 2400th batch is: 10.901951\n","the loss in 2600th batch is: 10.917852\n","the loss in 2800th batch is: 10.902759\n","the loss in 3000th batch is: 10.835882\n","the loss in 3200th batch is: 10.882853\n","the loss in 3400th batch is: 10.828333\n","the loss in 3600th batch is: 10.792470\n","the loss in 3800th batch is: 10.693182\n","the loss in 4000th batch is: 10.663772\n","the loss in 4200th batch is: 10.592307\n","the loss in 4400th batch is: 10.534250\n","the loss in 4600th batch is: 10.342700\n","the loss in 4800th batch is: 10.581702\n","the loss in 5000th batch is: 10.789047\n","the loss in 5200th batch is: 10.352245\n","the loss in 5400th batch is: 10.623329\n","the loss in 5600th batch is: 10.223569\n","the loss in 5800th batch is: 10.330580\n","the loss in 6000th batch is: 10.464149\n","the loss in 6200th batch is: 10.317551\n","the loss in 6400th batch is: 10.256943\n","the loss in 6600th batch is: 10.343325\n","the loss in 6800th batch is: 10.366439\n","the loss in 7000th batch is: 10.228130\n","the loss in 7200th batch is: 10.197817\n","the loss in 7400th batch is: 10.316353\n","the loss in 7600th batch is: 10.064329\n","the loss in 7800th batch is: 10.240582\n","the loss in 8000th batch is: 10.071001\n","the loss in 8200th batch is: 10.155104\n","the loss in 8400th batch is: 10.186701\n","the loss in 8600th batch is: 10.592416\n","the loss in 8800th batch is: 10.287948\n","the loss in 9000th batch is: 10.131128\n","the loss in 9200th batch is: 10.255369\n","the loss in 9400th batch is: 10.060040\n","the loss in 9600th batch is: 10.205731\n","the loss in 9800th batch is: 10.101375\n","the loss in 10000th batch is: 10.188779\n","the loss in 10200th batch is: 10.073606\n","the loss in 10400th batch is: 10.249131\n","the loss in 10600th batch is: 9.862673\n","the loss in 10800th batch is: 9.899236\n","the loss in 11000th batch is: 9.824553\n","the loss in 11200th batch is: 9.776564\n","the loss in 11400th batch is: 9.970218\n","the loss in 11600th batch is: 9.820200\n","the loss in 11800th batch is: 9.811543\n","the loss in 12000th batch is: 10.128112\n","the loss in 12200th batch is: 9.595634\n","the loss in 12400th batch is: 9.822469\n","the loss in 12600th batch is: 9.896150\n","the loss in 12800th batch is: 9.846256\n","the loss in 13000th batch is: 9.577015\n","the loss in 13200th batch is: 9.735275\n","the loss in 13400th batch is: 9.894041\n","the loss in 13600th batch is: 9.709919\n","the loss in 13800th batch is: 9.676779\n","the loss in 14000th batch is: 9.823704\n","the loss in 14200th batch is: 9.844161\n","the loss in 14400th batch is: 9.912076\n","the loss in 14600th batch is: 9.768517\n","the loss in 14800th batch is: 9.754499\n","the loss in 15000th batch is: 10.073950\n","the loss in 15200th batch is: 9.544374\n","the loss in 15400th batch is: 9.809994\n","the loss in 15600th batch is: 9.743114\n","the loss in 15800th batch is: 9.629857\n","the loss in 16000th batch is: 9.733980\n","the loss in 16200th batch is: 9.519453\n","the loss in 16400th batch is: 9.606567\n","the loss in 16600th batch is: 9.723495\n","the loss in 16800th batch is: 9.433899\n","the loss in 17000th batch is: 9.543375\n","the loss in 17200th batch is: 9.667685\n","the loss in 17400th batch is: 9.167085\n","the loss in 17600th batch is: 9.484268\n","the loss in 17800th batch is: 9.605248\n","the loss in 18000th batch is: 9.622742\n","the loss in 18200th batch is: 9.470080\n","the loss in 18400th batch is: 9.464366\n","the loss in 18600th batch is: 9.472908\n","the loss in 18800th batch is: 9.368046\n","the loss in 19000th batch is: 9.582174\n","the loss in 19200th batch is: 9.652044\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 3891.200000\n","clicks hr ndcg @ 5 : 0.107273, 0.090943\n","purchase hr and ndcg @5 : 0.255717, 0.220330\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 4361.000000\n","clicks hr ndcg @ 10 : 0.120493, 0.095217\n","purchase hr and ndcg @10 : 0.285390, 0.229856\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 4640.800000\n","clicks hr ndcg @ 15 : 0.128768, 0.097402\n","purchase hr and ndcg @15 : 0.301266, 0.234081\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 4813.200000\n","clicks hr ndcg @ 20 : 0.133814, 0.098596\n","purchase hr and ndcg @20 : 0.311283, 0.236437\n","#############################################################\n"]}],"source":["! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.1"]},{"cell_type":"markdown","metadata":{},"source":["### lambda 0.2"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T00:02:12.252571Z","iopub.status.busy":"2023-11-25T00:02:12.251638Z","iopub.status.idle":"2023-11-25T01:24:45.835946Z","shell.execute_reply":"2023-11-25T01:24:45.834731Z","shell.execute_reply.started":"2023-11-25T00:02:12.252528Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:85: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:212: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:215: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:217: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.features_layer = tf.compat.v1.layers.dense(self.features,self.hidden_size,use_bias=True,activation = None)\n","the loss in 200th batch is: 11.384401\n","the loss in 400th batch is: 11.649719\n","the loss in 600th batch is: 11.657927\n","the loss in 800th batch is: 11.368053\n","the loss in 1000th batch is: 11.073269\n","the loss in 1200th batch is: 11.001225\n","the loss in 1400th batch is: 10.909673\n","the loss in 1600th batch is: 11.184868\n","the loss in 1800th batch is: 10.855921\n","the loss in 2000th batch is: 10.886360\n","the loss in 2200th batch is: 10.734078\n","the loss in 2400th batch is: 10.900715\n","the loss in 2600th batch is: 11.056023\n","the loss in 2800th batch is: 10.669811\n","the loss in 3000th batch is: 10.665911\n","the loss in 3200th batch is: 10.540492\n","the loss in 3400th batch is: 10.498845\n","the loss in 3600th batch is: 10.428552\n","the loss in 3800th batch is: 10.424718\n","the loss in 4000th batch is: 10.234807\n","the loss in 4200th batch is: 10.300573\n","the loss in 4400th batch is: 10.458965\n","the loss in 4600th batch is: 10.257224\n","the loss in 4800th batch is: 10.205543\n","the loss in 5000th batch is: 10.204609\n","the loss in 5200th batch is: 10.334306\n","the loss in 5400th batch is: 10.013392\n","the loss in 5600th batch is: 10.108360\n","the loss in 5800th batch is: 10.222851\n","the loss in 6000th batch is: 9.909781\n","the loss in 6200th batch is: 10.355738\n","the loss in 6400th batch is: 10.112597\n","the loss in 6600th batch is: 10.060098\n","the loss in 6800th batch is: 10.170087\n","the loss in 7000th batch is: 9.958397\n","the loss in 7200th batch is: 10.222198\n","the loss in 7400th batch is: 9.785015\n","the loss in 7600th batch is: 9.984900\n","the loss in 7800th batch is: 9.993970\n","the loss in 8000th batch is: 9.705482\n","the loss in 8200th batch is: 9.913551\n","the loss in 8400th batch is: 9.915065\n","the loss in 8600th batch is: 9.730977\n","the loss in 8800th batch is: 9.831229\n","the loss in 9000th batch is: 9.985495\n","the loss in 9200th batch is: 9.803696\n","the loss in 9400th batch is: 9.815256\n","the loss in 9600th batch is: 9.600285\n","the loss in 9800th batch is: 9.512815\n","the loss in 10000th batch is: 9.711835\n","the loss in 10200th batch is: 9.796366\n","the loss in 10400th batch is: 9.753469\n","the loss in 10600th batch is: 9.759079\n","the loss in 10800th batch is: 9.872703\n","the loss in 11000th batch is: 9.667906\n","the loss in 11200th batch is: 9.464225\n","the loss in 11400th batch is: 9.464090\n","the loss in 11600th batch is: 9.966856\n","the loss in 11800th batch is: 9.419952\n","the loss in 12000th batch is: 9.494701\n","the loss in 12200th batch is: 9.649454\n","the loss in 12400th batch is: 9.464436\n","the loss in 12600th batch is: 9.717066\n","the loss in 12800th batch is: 9.521943\n","the loss in 13000th batch is: 9.567820\n","the loss in 13200th batch is: 9.646673\n","the loss in 13400th batch is: 9.720377\n","the loss in 13600th batch is: 9.745599\n","the loss in 13800th batch is: 9.777898\n","the loss in 14000th batch is: 9.704266\n","the loss in 14200th batch is: 9.698408\n","the loss in 14400th batch is: 9.245207\n","the loss in 14600th batch is: 9.365112\n","the loss in 14800th batch is: 9.219707\n","the loss in 15400th batch is: 9.365973\n","the loss in 15600th batch is: 9.599714\n","the loss in 15800th batch is: 9.411700\n","the loss in 16000th batch is: 9.707010\n","the loss in 16200th batch is: 9.155495\n","the loss in 16400th batch is: 9.230206\n","the loss in 16600th batch is: 9.362397\n","the loss in 16800th batch is: 9.452727\n","the loss in 17000th batch is: 9.391045\n","the loss in 17200th batch is: 9.008738\n","the loss in 17400th batch is: 9.440377\n","the loss in 17600th batch is: 9.295126\n","the loss in 17800th batch is: 9.441964\n","the loss in 18000th batch is: 8.719279\n","the loss in 18200th batch is: 9.303836\n","the loss in 18400th batch is: 9.209266\n","the loss in 18600th batch is: 9.364197\n","the loss in 18800th batch is: 9.496109\n","the loss in 19000th batch is: 9.152137\n","the loss in 19200th batch is: 9.531954\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 3963.600000\n","clicks hr ndcg @ 5 : 0.109741, 0.093468\n","purchase hr and ndcg @5 : 0.258363, 0.227042\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 4369.800000\n","clicks hr ndcg @ 10 : 0.122471, 0.097577\n","purchase hr and ndcg @10 : 0.278208, 0.233413\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 4616.000000\n","clicks hr ndcg @ 15 : 0.130129, 0.099607\n","purchase hr and ndcg @15 : 0.290493, 0.236654\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 4814.200000\n","clicks hr ndcg @ 20 : 0.135885, 0.100969\n","purchase hr and ndcg @20 : 0.302211, 0.239430\n","#############################################################\n"]}],"source":["! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.2"]},{"cell_type":"markdown","metadata":{},"source":["### lambda 0.5"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T01:30:46.218581Z","iopub.status.busy":"2023-11-25T01:30:46.218240Z","iopub.status.idle":"2023-11-25T02:53:24.656347Z","shell.execute_reply":"2023-11-25T02:53:24.655299Z","shell.execute_reply.started":"2023-11-25T01:30:46.218554Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:85: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:212: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:215: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/kaggle/working/Kaggle/SNQN_new_with_features.py:217: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.features_layer = tf.compat.v1.layers.dense(self.features,self.hidden_size,use_bias=True,activation = None)\n","the loss in 200th batch is: 11.359965\n","the loss in 400th batch is: 11.510338\n","the loss in 600th batch is: 11.642828\n","the loss in 800th batch is: 11.231221\n","the loss in 1000th batch is: 10.961859\n","the loss in 1200th batch is: 10.865892\n","the loss in 1400th batch is: 10.730684\n","the loss in 1600th batch is: 10.638948\n","the loss in 1800th batch is: 10.593769\n","the loss in 2000th batch is: 10.550879\n","the loss in 2200th batch is: 10.646200\n","the loss in 2400th batch is: 10.566029\n","the loss in 2600th batch is: 10.661630\n","the loss in 2800th batch is: 10.340390\n","the loss in 3000th batch is: 10.493116\n","the loss in 3200th batch is: 10.391886\n","the loss in 3400th batch is: 10.147554\n","the loss in 3600th batch is: 10.229715\n","the loss in 3800th batch is: 10.482197\n","the loss in 4000th batch is: 10.148531\n","the loss in 4200th batch is: 10.128680\n","the loss in 4400th batch is: 9.836557\n","the loss in 4600th batch is: 10.058531\n","the loss in 4800th batch is: 10.283908\n","the loss in 5000th batch is: 10.094037\n","the loss in 5200th batch is: 10.181755\n","the loss in 5400th batch is: 10.030272\n","the loss in 5600th batch is: 9.764321\n","the loss in 5800th batch is: 9.931023\n","the loss in 6000th batch is: 10.214111\n","the loss in 6200th batch is: 10.062959\n","the loss in 6400th batch is: 9.645260\n","the loss in 6600th batch is: 9.758479\n","the loss in 6800th batch is: 9.511454\n","the loss in 7000th batch is: 9.776035\n","the loss in 7200th batch is: 9.639386\n","the loss in 7400th batch is: 9.904753\n","the loss in 7600th batch is: 9.659137\n","the loss in 7800th batch is: 10.004297\n","the loss in 8000th batch is: 9.478548\n","the loss in 8200th batch is: 9.713839\n","the loss in 8400th batch is: 9.770804\n","the loss in 8600th batch is: 9.596298\n","the loss in 8800th batch is: 9.569574\n","the loss in 9000th batch is: 9.421570\n","the loss in 9200th batch is: 9.819721\n","the loss in 9400th batch is: 9.571566\n","the loss in 9600th batch is: 9.354974\n","the loss in 9800th batch is: 9.715151\n","the loss in 10000th batch is: 9.766763\n","the loss in 10200th batch is: 9.494504\n","the loss in 10400th batch is: 9.670824\n","the loss in 10600th batch is: 9.536507\n","the loss in 10800th batch is: 9.845314\n","the loss in 11000th batch is: 9.146259\n","the loss in 11200th batch is: 9.335252\n","the loss in 11400th batch is: 9.437737\n","the loss in 11600th batch is: 9.388317\n","the loss in 11800th batch is: 9.472205\n","the loss in 12000th batch is: 9.573500\n","the loss in 12200th batch is: 9.272961\n","the loss in 12400th batch is: 9.652887\n","the loss in 12600th batch is: 9.612414\n","the loss in 12800th batch is: 9.206966\n","the loss in 13000th batch is: 9.269882\n","the loss in 13200th batch is: 9.226505\n","the loss in 13400th batch is: 9.518206\n","the loss in 13600th batch is: 9.164281\n","the loss in 13800th batch is: 9.002638\n","the loss in 14000th batch is: 9.210176\n","the loss in 14200th batch is: 9.249884\n","the loss in 14400th batch is: 9.310110\n","the loss in 14600th batch is: 9.405004\n","the loss in 14800th batch is: 9.215043\n","the loss in 15000th batch is: 9.335710\n","the loss in 15200th batch is: 9.132017\n","the loss in 15400th batch is: 9.059520\n","the loss in 15600th batch is: 9.326094\n","the loss in 15800th batch is: 9.431902\n","the loss in 16000th batch is: 8.876199\n","the loss in 16200th batch is: 9.631177\n","the loss in 16400th batch is: 9.123350\n","the loss in 16600th batch is: 9.003356\n","the loss in 16800th batch is: 8.970897\n","the loss in 17000th batch is: 9.058794\n","the loss in 17200th batch is: 9.160171\n","the loss in 17400th batch is: 9.237162\n","the loss in 17600th batch is: 9.134917\n","the loss in 17800th batch is: 9.147422\n","the loss in 18000th batch is: 9.360640\n","the loss in 18200th batch is: 8.831514\n","the loss in 18400th batch is: 9.427008\n","the loss in 18600th batch is: 9.335590\n","the loss in 18800th batch is: 9.275072\n","the loss in 19000th batch is: 9.172598\n","the loss in 19200th batch is: 9.225149\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 3709.600000\n","clicks hr ndcg @ 5 : 0.102767, 0.087199\n","purchase hr and ndcg @5 : 0.241542, 0.210101\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 4168.200000\n","clicks hr ndcg @ 10 : 0.115599, 0.091354\n","purchase hr and ndcg @10 : 0.270837, 0.219610\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 4429.000000\n","clicks hr ndcg @ 15 : 0.123705, 0.093495\n","purchase hr and ndcg @15 : 0.283878, 0.223066\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 4611.800000\n","clicks hr ndcg @ 20 : 0.129148, 0.094784\n","purchase hr and ndcg @20 : 0.294084, 0.225473\n","#############################################################\n"]}],"source":["! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
