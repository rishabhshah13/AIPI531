{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe6jIQxyHr5v",
        "outputId": "b6e3f45d-8e2c-40ea-d4fc-5ebedb326e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle\n",
            "data\t\t     preprocess_kaggle.py  report_SNQN.txt   SNQN_new.py\t\ttest.py\n",
            "DQN_NS.py\t     __pycache__\t   SA2C_new.py\t     SNQN_new_with_features.py\tutility.py\n",
            "NextItNetModules.py  replay_buffer.py\t   SA2C.py\t     SNQN.py\n",
            "pop.py\t\t     report_SA2C.txt\t   SASRecModules.py  split_data.py\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive folder\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "project_loc = '/content/drive/MyDrive/AIPI 531 HW3/Kaggle/'\n",
        "# project_loc = '/Users/rishabhshah/Desktop/AIPI531/HW3/Kaggle/'\n",
        "%cd $project_loc\n",
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BlGmKufIcBQ"
      },
      "source": [
        "Using https://www.tensorflow.org/guide/migrate/upgrade to change code of SNQN and SA2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07gS5tgQNQyJ"
      },
      "outputs": [],
      "source": [
        "# !tf_upgrade_v2 \\\n",
        "#   --infile 'SNQN.py' \\\n",
        "#   --outfile 'SNQN_new.py' \\\n",
        "#   --reportfile report_SNQN.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yvq5LfWyYYGp"
      },
      "outputs": [],
      "source": [
        "## Addtional Changes\n",
        "#1. Added 'tf.compat.v1.disable_eager_execution()' after init()\n",
        "#2. Replaced 'tf.contrib.layers.fully_connected' with 'tf.compat.v1.layers.dense' near line 207\n",
        "#3. Changed 'activation_fn' to 'activation'\n",
        "#4. Changed 'scope' to 'name'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcOUmyaTIDI6"
      },
      "outputs": [],
      "source": [
        "# !tf_upgrade_v2 \\\n",
        "#   --infile 'SA2C.py' \\\n",
        "#   --outfile 'SA2C_new.py' \\\n",
        "#   --reportfile report_SA2C.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4isH4u9tW7tK",
        "outputId": "5f91ebf6-a3e9-4585-b2f3-c3c1035c9f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/104.3 kB\u001b[0m \u001b[31m777.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trfl) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install trfl pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FjTNnfMak6O"
      },
      "source": [
        "## SNQN without features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxrSvJ0uITpm",
        "outputId": "18044b95-1863-43eb-fe9a-1e07f404a61c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-24 18:39:11.503646: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 18:39:11.503703: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 18:39:11.503748: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 18:39:11.514485: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 18:39:13.400808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new.py:80: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new.py:79: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "2023-11-24 18:39:18.126743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:18.167421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:18.167789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:18.169462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:18.169756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:18.169977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:19.291715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:19.292141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:19.292310: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-24 18:39:19.292394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:19.292583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new.py:207: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new.py:210: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "2023-11-24 18:39:25.375360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:25.375720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:25.375919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:25.376152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:25.376325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 18:39:25.376459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-11-24 18:39:25.400589: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.000000\n",
            "clicks hr ndcg @ 5 : 0.000042, 0.000030\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.800000\n",
            "clicks hr ndcg @ 10 : 0.000118, 0.000054\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 5.000000\n",
            "clicks hr ndcg @ 15 : 0.000169, 0.000067\n",
            "purchase hr and ndcg @15 : 0.000189, 0.000051\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6.600000\n",
            "clicks hr ndcg @ 20 : 0.000237, 0.000083\n",
            "purchase hr and ndcg @20 : 0.000189, 0.000051\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.831070\n",
            "the loss in 400th batch is: 10.708863\n",
            "the loss in 600th batch is: 10.473969\n",
            "the loss in 800th batch is: 10.256775\n",
            "the loss in 1000th batch is: 10.302694\n",
            "the loss in 1200th batch is: 10.187847\n",
            "the loss in 1400th batch is: 9.911209\n",
            "the loss in 1600th batch is: 9.684079\n",
            "the loss in 1800th batch is: 9.965717\n",
            "the loss in 2000th batch is: 9.596400\n",
            "the loss in 2200th batch is: 9.612836\n",
            "the loss in 2400th batch is: 9.414681\n",
            "the loss in 2600th batch is: 9.315511\n",
            "the loss in 2800th batch is: 9.027935\n",
            "the loss in 3000th batch is: 8.892451\n",
            "the loss in 3200th batch is: 8.695235\n",
            "the loss in 3400th batch is: 9.019030\n",
            "the loss in 3600th batch is: 8.995421\n",
            "the loss in 3800th batch is: 8.723010\n",
            "the loss in 4000th batch is: 8.671647\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5940.200000\n",
            "clicks hr ndcg @ 5 : 0.170456, 0.134840\n",
            "purchase hr and ndcg @5 : 0.360423, 0.307851\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6870.200000\n",
            "clicks hr ndcg @ 10 : 0.201816, 0.144975\n",
            "purchase hr and ndcg @10 : 0.395955, 0.319366\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7418.000000\n",
            "clicks hr ndcg @ 15 : 0.220403, 0.149887\n",
            "purchase hr and ndcg @15 : 0.416367, 0.324739\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7792.600000\n",
            "clicks hr ndcg @ 20 : 0.232981, 0.152860\n",
            "purchase hr and ndcg @20 : 0.430920, 0.328163\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.361216\n",
            "the loss in 4400th batch is: 8.552400\n",
            "the loss in 4600th batch is: 7.998997\n",
            "the loss in 4800th batch is: 8.344571\n",
            "the loss in 5000th batch is: 8.101270\n",
            "the loss in 5200th batch is: 8.191595\n",
            "the loss in 5400th batch is: 8.073001\n",
            "the loss in 5600th batch is: 7.812063\n",
            "the loss in 5800th batch is: 8.138997\n",
            "the loss in 6000th batch is: 7.824451\n",
            "the loss in 6200th batch is: 7.857933\n",
            "the loss in 6400th batch is: 8.025812\n",
            "the loss in 6600th batch is: 7.361782\n",
            "the loss in 6800th batch is: 7.613865\n",
            "the loss in 7000th batch is: 7.781521\n",
            "the loss in 7200th batch is: 6.623374\n",
            "the loss in 7400th batch is: 7.506742\n",
            "the loss in 7600th batch is: 7.225129\n",
            "the loss in 7800th batch is: 6.936631\n",
            "the loss in 8000th batch is: 6.949760\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8064.400000\n",
            "clicks hr ndcg @ 5 : 0.233057, 0.183372\n",
            "purchase hr and ndcg @5 : 0.481950, 0.409364\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 9328.000000\n",
            "clicks hr ndcg @ 10 : 0.276360, 0.197434\n",
            "purchase hr and ndcg @10 : 0.527122, 0.424063\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9988.000000\n",
            "clicks hr ndcg @ 15 : 0.300027, 0.203699\n",
            "purchase hr and ndcg @15 : 0.546022, 0.429086\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10433.600000\n",
            "clicks hr ndcg @ 20 : 0.315605, 0.207381\n",
            "purchase hr and ndcg @20 : 0.560575, 0.432511\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 6.839231\n",
            "the loss in 8400th batch is: 7.218547\n",
            "the loss in 8600th batch is: 7.160608\n",
            "the loss in 8800th batch is: 6.967088\n",
            "the loss in 9000th batch is: 7.171959\n",
            "the loss in 9200th batch is: 6.938854\n",
            "the loss in 9400th batch is: 6.981570\n",
            "the loss in 9600th batch is: 7.089956\n",
            "the loss in 9800th batch is: 7.041745\n",
            "the loss in 10000th batch is: 6.930947\n",
            "the loss in 10200th batch is: 6.663842\n",
            "the loss in 10400th batch is: 6.510228\n",
            "the loss in 10600th batch is: 7.135838\n",
            "the loss in 10800th batch is: 6.751001\n",
            "the loss in 11000th batch is: 6.576570\n",
            "the loss in 11200th batch is: 7.032478\n",
            "the loss in 11400th batch is: 6.265667\n",
            "the loss in 11600th batch is: 6.681502\n",
            "the loss in 11800th batch is: 6.254086\n",
            "the loss in 12000th batch is: 6.369989\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8708.000000\n",
            "clicks hr ndcg @ 5 : 0.253326, 0.198155\n",
            "purchase hr and ndcg @5 : 0.512947, 0.434688\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 10106.200000\n",
            "clicks hr ndcg @ 10 : 0.301219, 0.213680\n",
            "purchase hr and ndcg @10 : 0.563032, 0.450917\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 10873.200000\n",
            "clicks hr ndcg @ 15 : 0.327845, 0.220731\n",
            "purchase hr and ndcg @15 : 0.588925, 0.457769\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11374.600000\n",
            "clicks hr ndcg @ 20 : 0.345359, 0.224869\n",
            "purchase hr and ndcg @20 : 0.605368, 0.461658\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.724877\n",
            "the loss in 12400th batch is: 5.665309\n",
            "the loss in 12600th batch is: 6.381378\n",
            "the loss in 12800th batch is: 6.546963\n",
            "the loss in 13000th batch is: 6.054119\n",
            "the loss in 13200th batch is: 5.864646\n",
            "the loss in 13400th batch is: 6.064337\n",
            "the loss in 13600th batch is: 6.098983\n",
            "the loss in 13800th batch is: 6.247651\n",
            "the loss in 14000th batch is: 6.568443\n",
            "the loss in 14200th batch is: 6.168731\n",
            "the loss in 14400th batch is: 6.083386\n",
            "the loss in 14600th batch is: 5.900432\n",
            "the loss in 14800th batch is: 6.356135\n",
            "the loss in 15000th batch is: 6.035924\n",
            "the loss in 15200th batch is: 5.989168\n",
            "the loss in 15400th batch is: 6.179874\n",
            "the loss in 15600th batch is: 5.855539\n",
            "the loss in 15800th batch is: 6.273185\n",
            "the loss in 16000th batch is: 6.152060\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8999.200000\n",
            "clicks hr ndcg @ 5 : 0.262083, 0.204893\n",
            "purchase hr and ndcg @5 : 0.528823, 0.446596\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 10404.200000\n",
            "clicks hr ndcg @ 10 : 0.311911, 0.221044\n",
            "purchase hr and ndcg @10 : 0.571537, 0.460551\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 11196.600000\n",
            "clicks hr ndcg @ 15 : 0.339569, 0.228370\n",
            "purchase hr and ndcg @15 : 0.597619, 0.467468\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11701.600000\n",
            "clicks hr ndcg @ 20 : 0.358207, 0.232771\n",
            "purchase hr and ndcg @20 : 0.609715, 0.470330\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 5.871507\n",
            "the loss in 16400th batch is: 5.680054\n",
            "the loss in 16600th batch is: 5.618833\n",
            "the loss in 16800th batch is: 5.869767\n",
            "the loss in 17000th batch is: 6.183516\n",
            "the loss in 17200th batch is: 6.071755\n",
            "the loss in 17400th batch is: 5.566697\n",
            "the loss in 17600th batch is: 5.841672\n",
            "the loss in 17800th batch is: 6.241893\n",
            "the loss in 18000th batch is: 6.068083\n",
            "the loss in 18200th batch is: 5.750560\n",
            "the loss in 18400th batch is: 5.939715\n",
            "the loss in 18600th batch is: 5.691626\n",
            "the loss in 18800th batch is: 5.959230\n",
            "the loss in 19000th batch is: 5.545290\n",
            "the loss in 19200th batch is: 5.810257\n"
          ]
        }
      ],
      "source": [
        "# ! python SNQN_new.py --model=GRU --epoch=5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjdXc3zlbz-m"
      },
      "source": [
        "## SNQN with Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyAc-c4AZF-a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/AIPI 531 HW3/Kaggle/data/item_prop_ohe.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QDEP-4J4kzmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334809c0-6c17-46b4-91c0-292161906aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-24 22:16:54.492912: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 22:16:54.492972: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 22:16:54.493015: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 22:16:54.515703: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 22:16:56.210561: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new_with_features.py:85: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new_with_features.py:84: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new_with_features.py:212: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new_with_features.py:215: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new_with_features.py:217: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.features_layer = tf.compat.v1.layers.dense(self.features,self.hidden_size,use_bias=True,activation = None)\n",
            "2023-11-24 22:17:15.912428: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 2.200000\n",
            "clicks hr ndcg @ 5 : 0.000093, 0.000054\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 4.800000\n",
            "clicks hr ndcg @ 10 : 0.000203, 0.000089\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8.600000\n",
            "clicks hr ndcg @ 15 : 0.000321, 0.000120\n",
            "purchase hr and ndcg @15 : 0.000189, 0.000053\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11.800000\n",
            "clicks hr ndcg @ 20 : 0.000414, 0.000142\n",
            "purchase hr and ndcg @20 : 0.000378, 0.000097\n",
            "#############################################################\n",
            "the loss in 200th batch is: 11.440716\n",
            "the loss in 400th batch is: 11.651473\n",
            "the loss in 600th batch is: 11.588536\n",
            "the loss in 800th batch is: 11.960653\n",
            "the loss in 1000th batch is: 11.257978\n",
            "the loss in 1200th batch is: 11.266405\n",
            "the loss in 1400th batch is: 10.976116\n",
            "the loss in 1600th batch is: 11.003472\n",
            "the loss in 1800th batch is: 11.086887\n",
            "the loss in 2000th batch is: 10.920896\n",
            "the loss in 2200th batch is: 10.958138\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/AIPI 531 HW3/Kaggle/SNQN_new_with_features.py\", line 429, in <module>\n",
            "    loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 972, in run\n",
            "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 1215, in _run\n",
            "    results = self._do_run(handle, final_targets, final_fetches,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 1395, in _do_run\n",
            "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 1402, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 1385, in _run_fn\n",
            "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 1478, in _call_tf_sessionrun\n",
            "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zGmrAIkcosv"
      },
      "outputs": [],
      "source": [
        "! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DgcgFuzdb2A"
      },
      "outputs": [],
      "source": [
        "! python SNQN_new_with_features.py --model=GRU --epoch=5 --item_features_loc=item_prop_ohe.csv --lamda_value=0.5"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}