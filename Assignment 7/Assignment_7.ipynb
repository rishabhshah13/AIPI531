{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnw25CoE9CqtBbWXnBdmGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishabhshah13/AIPI531/blob/main/Assignment%207/Assignment_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "# !pip install tensorflow keras tcav"
      ],
      "metadata": {
        "id": "AhPNANszvSDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tcav.tcav import TCAV\n",
        "from tcav.utils import create_session, make_dir_if_not_exists\n",
        "from tcav.model import KerasModelWrapper\n",
        "from tcav.cav import CAV\n",
        "from tcav.utils import process_what_to_run_expand\n",
        "\n",
        "# Set up paths for data and results\n",
        "import os"
      ],
      "metadata": {
        "id": "EWPQ59Xdv9tQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/tcav'\n",
        "concepts_dir = os.path.join(base_dir, 'concepts')\n",
        "images_dir = os.path.join(base_dir, 'images')\n",
        "results_dir = os.path.join(base_dir, 'results')\n",
        "\n",
        "make_dir_if_not_exists(base_dir)\n",
        "make_dir_if_not_exists(concepts_dir)\n",
        "make_dir_if_not_exists(images_dir)\n",
        "make_dir_if_not_exists(results_dir)"
      ],
      "metadata": {
        "id": "OMoNlFOMv_RG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt -o imagenet_labels.txt"
      ],
      "metadata": {
        "id": "mF66hoagwadz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained ResNet50 model\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "# The KerasModelWrapper expects paths, not the model object itself.\n",
        "# We need to save the model and labels to disk then provide those paths\n",
        "# **Change: Save the model BEFORE disabling eager execution**\n",
        "model.save(os.path.join(results_dir, 'resnet50.h5'))\n",
        "\n",
        "# Replace with the actual path to your ImageNet labels file\n",
        "labels_path = 'imagenet_labels.txt'\n",
        "\n",
        "# **Change: Disable eager execution AFTER saving the model**\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# Create a TensorFlow session\n",
        "sess = tf.compat.v1.Session()\n",
        "\n",
        "# Initialize KerasModelWrapper with the session\n",
        "model_wrapper = KerasModelWrapper(sess, model_path=os.path.join(results_dir, 'resnet50.h5'), labels_path=labels_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "HUV_eVWDwCT1",
        "outputId": "d3dea6ce-af57-4ef2-cb0a-4d5c25d041dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Functional' object has no attribute 'loss_functions'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4e1659527604>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Initialize KerasModelWrapper with the session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet50.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tcav/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess, model_path, labels_path)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Construct gradient ops. Defaults to using the model's output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     self.loss = self.model.loss_functions[0](self.y_input,\n\u001b[0m\u001b[1;32m    450\u001b[0m                                              self.model.outputs[0])\n\u001b[1;32m    451\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_gradient_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'loss_functions'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assume you have functions to load your images and concepts\n",
        "def load_concepts():\n",
        "    # Implement loading of striped and dotted images into respective directories\n",
        "    pass\n",
        "\n",
        "def load_images():\n",
        "    # Implement loading of zebra images into images directory\n",
        "    pass\n",
        "\n",
        "load_concepts()\n",
        "load_images()\n",
        "\n",
        "# Define target class and concepts\n",
        "target = 'zebra'\n",
        "concepts = ['striped', 'dotted']\n",
        "\n",
        "# Prepare TCAV parameters\n",
        "bottlenecks = ['conv5_block3_out']  # Example bottleneck layer\n",
        "alphas = [0.1]  # Regularization parameter for CAV\n",
        "\n",
        "# Run TCAV\n",
        "session = create_session()\n",
        "tcav_instance = TCAV(session, target, concepts, bottlenecks, alphas, model_wrapper, images_dir, results_dir)\n",
        "\n",
        "results = tcav_instance.run()\n",
        "\n",
        "# Visualize results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results(results):\n",
        "    for result in results:\n",
        "        if result['target_class'] == target:\n",
        "            print(f\"TCAV score for {result['concept']}: {result['i_up']}\")\n",
        "\n",
        "plot_results(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "i7nu2WJqvW-2",
        "outputId": "aedb4b5b-4b27-4e64-f2d8-a21d8380805b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "KerasModelWrapper.__init__() missing 2 required positional arguments: 'model_path' and 'labels_path'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7988b08c58a6>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Load pre-trained ResNet50 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Assume you have functions to load your images and concepts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: KerasModelWrapper.__init__() missing 2 required positional arguments: 'model_path' and 'labels_path'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZFRorNEJvwzz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}